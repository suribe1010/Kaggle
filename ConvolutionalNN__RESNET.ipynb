{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvolutionalNN_ RESNET",
      "provenance": [],
      "authorship_tag": "ABX9TyOVB2NtuM0a+8eLdItmepDR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suribe1010/Kaggle/blob/master/ConvolutionalNN__RESNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw18vyDPaw5X",
        "colab_type": "text"
      },
      "source": [
        "THIS IS AN EXAMPLE OF A CONVOLUTIONAL NEURAL NETWORK WITH RESNET ARCHITECTURE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC_yc9aza7je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMPORT PACKAGES\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,AveragePooling2D,Dropout,BatchNormalization,Activation\n",
        "from keras.models import Model,Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from math import ceil\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCkwznebd7g4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LOAD THE CIFAR10 DATASET\n",
        "\n",
        "(train_x, train_y) , (test_x, test_y) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQmxn_-9eKhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5bbca761-4332-4ab3-bd31-883be2958435"
      },
      "source": [
        "train_x.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DOjniNEeOpp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "outputId": "fe38c588-6c88-4c28-87f1-9f1f7796f265"
      },
      "source": [
        "train_x[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdybTyjnef6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "9d1115db-b5bf-46a2-d932-da4ba2b31396"
      },
      "source": [
        "print('Shape of each element (32 elements) of 1st example: ', train_x[0][0].shape)\n",
        "train_x[0][0]\n",
        "train_x[0][31]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of each element (32 elements) of 1st example:  (32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[177, 144, 116],\n",
              "       [168, 129,  94],\n",
              "       [179, 142,  87],\n",
              "       [188, 149,  67],\n",
              "       [202, 168,  68],\n",
              "       [218, 189,  76],\n",
              "       [218, 191,  72],\n",
              "       [207, 181,  70],\n",
              "       [191, 163,  79],\n",
              "       [175, 143,  82],\n",
              "       [166, 132,  86],\n",
              "       [163, 128,  92],\n",
              "       [163, 127,  94],\n",
              "       [161, 123,  92],\n",
              "       [153, 114,  84],\n",
              "       [159, 120,  90],\n",
              "       [162, 124,  93],\n",
              "       [149, 116,  91],\n",
              "       [140, 104,  83],\n",
              "       [148, 103,  77],\n",
              "       [161, 105,  69],\n",
              "       [144,  95,  55],\n",
              "       [112,  90,  59],\n",
              "       [119,  91,  58],\n",
              "       [130,  96,  65],\n",
              "       [120,  87,  59],\n",
              "       [ 92,  67,  46],\n",
              "       [103,  78,  57],\n",
              "       [170, 140, 104],\n",
              "       [216, 184, 140],\n",
              "       [151, 118,  84],\n",
              "       [123,  92,  72]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LgI90qtfTQC",
        "colab_type": "text"
      },
      "source": [
        "There are 32 matrixes of size (32,3) as the one before in 1 example.\n",
        "There are 50000 examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgZyaxHJfo3J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "bf689516-ce05-4753-d8f4-973752fddec3"
      },
      "source": [
        "# NORMALIZATION OF THE DATA\n",
        "\n",
        "train_x = train_x.astype('float32') / 255\n",
        "test_x = test_x.astype('float32') / 255\n",
        "\n",
        "train_x = train_x - train_x.mean()\n",
        "test_x = test_x - test_x.mean()\n",
        "\n",
        "train_x = train_x / train_x.std(axis=0)\n",
        "test_x = test_x / test_x.std(axis=0)\n",
        "\n",
        "train_x[0][0]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.84057784, -0.8052632 , -0.71733737],\n",
              "       [-1.0727214 , -1.0390277 , -0.95115703],\n",
              "       [-0.97879755, -1.0144184 , -0.97827077],\n",
              "       [-0.7318775 , -0.9332892 , -0.99340624],\n",
              "       [-0.31664565, -0.67041355, -0.8701512 ],\n",
              "       [-0.02387652, -0.41884312, -0.73228234],\n",
              "       [ 0.25636435, -0.19378802, -0.5810944 ],\n",
              "       [ 0.34079367, -0.15148064, -0.51818764],\n",
              "       [ 0.39808214, -0.05263771, -0.40490326],\n",
              "       [ 0.39828354, -0.01005867, -0.3538893 ],\n",
              "       [ 0.14522853, -0.2522744 , -0.5592571 ],\n",
              "       [ 0.06061345, -0.309664  , -0.5724796 ],\n",
              "       [ 0.30122873, -0.08149043, -0.3805845 ],\n",
              "       [ 0.3300301 , -0.12446555, -0.4451826 ],\n",
              "       [ 0.23101898, -0.22474778, -0.5356897 ],\n",
              "       [ 0.11756594, -0.33905846, -0.63824314],\n",
              "       [ 0.23092982, -0.21028787, -0.53551054],\n",
              "       [ 0.18834722, -0.2102308 , -0.57388633],\n",
              "       [ 0.04662099, -0.33857846, -0.7271696 ],\n",
              "       [ 0.258721  , -0.10995047, -0.5466715 ],\n",
              "       [ 0.2578694 , -0.12373962, -0.5831014 ],\n",
              "       [ 0.17305505, -0.22282812, -0.6587825 ],\n",
              "       [ 0.21498393, -0.22248526, -0.5945801 ],\n",
              "       [ 0.2572013 , -0.18005165, -0.55652416],\n",
              "       [ 0.4389766 , -0.01000835, -0.40280885],\n",
              "       [ 0.5925027 ,  0.14530219, -0.2628716 ],\n",
              "       [ 0.6608475 ,  0.21523872, -0.16099331],\n",
              "       [ 0.5335248 ,  0.11636882, -0.23652714],\n",
              "       [ 0.51671064,  0.12968369, -0.21033171],\n",
              "       [ 0.51530564,  0.1571405 , -0.15970813],\n",
              "       [ 0.43047377,  0.0594564 , -0.23441865],\n",
              "       [ 0.3729076 ,  0.04529762, -0.22095816]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX-5B8xNkBiI",
        "colab_type": "text"
      },
      "source": [
        "# DATA AUGMENTATION ????\n",
        "Antes de continuar, merece la pena explicar qué es data augmentation. La idea es que, cuando se dispone de un número de imágenes relativamente pequeño, podemos aumentar el número modificando las imágenes originales (haciendo zoom, escalado, flip horizontal, etc)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsdwYtDxglxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rotándola 10 grados y haciendo un flip horizontal.\n",
        "datagen = ImageDataGenerator(rotation_range=10,\n",
        "                             width_shift_range=5. / 32,\n",
        "                             height_shift_range=5. / 32,\n",
        "                             horizontal_flip=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbxLIaoMvQr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen.fit(train_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjMswaaGhcyS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "8089d3ff-a73d-4452-b3a7-96201c507dee"
      },
      "source": [
        "print('Shape of train labeled data: ', train_y.shape)\n",
        "train_y"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train labeled data:  (50000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmTTiW_8l3Nf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "67852cfe-b626-4a64-cca3-08dc08752557"
      },
      "source": [
        "# ENCODE THE LABELS TO VECTORS\n",
        "train_y = keras.utils.to_categorical(train_y,10)\n",
        "test_y = keras.utils.to_categorical(test_y,10)\n",
        "print('Shape of train labeled data: ', train_y.shape)\n",
        "train_y[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train labeled data:  (50000, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzn-RGzkn2X4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model\n",
        "\n",
        "def Unit(x,filters,pool=False):\n",
        "    res = x\n",
        "    if pool:\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "        res = Conv2D(filters=filters,kernel_size=[1,1],strides=(2,2),padding=\"same\")(res)\n",
        "    \n",
        "    out = BatchNormalization()(x)\n",
        "    out = Activation(\"relu\")(out)\n",
        "    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=\"same\")(out)\n",
        "\n",
        "    out = BatchNormalization()(out)\n",
        "    out = Activation(\"relu\")(out)\n",
        "    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=\"same\")(out)\n",
        "\n",
        "    out = keras.layers.add([res,out])\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def MiniModel(input_shape):\n",
        "    images = Input(input_shape)\n",
        "    net = Conv2D(filters=32, kernel_size=[3, 3], strides=[1, 1], padding=\"same\")(images)\n",
        "    net = Unit(net,32)\n",
        "    net = Unit(net,32)\n",
        "    net = Unit(net,32)\n",
        "\n",
        "    net = Unit(net,64,pool=True)\n",
        "    net = Unit(net,64)\n",
        "    net = Unit(net,64)\n",
        "\n",
        "    net = Unit(net,128,pool=True)\n",
        "    net = Unit(net,128)\n",
        "    net = Unit(net,128)\n",
        "\n",
        "    net = Unit(net, 256,pool=True)\n",
        "    net = Unit(net, 256)\n",
        "    net = Unit(net, 256)\n",
        "\n",
        "    net = BatchNormalization()(net)\n",
        "    net = Activation(\"relu\")(net)\n",
        "    net = Dropout(0.25)(net)\n",
        "\n",
        "    net = AveragePooling2D(pool_size=(4,4))(net)\n",
        "    net = Flatten()(net)\n",
        "    net = Dense(units=10,activation=\"softmax\")(net)\n",
        "\n",
        "    model = Model(inputs=images,outputs=net)\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYdYkuofskBf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9026ddc0-3c51-42f8-e8fe-21baa511afee"
      },
      "source": [
        "input_shape = (32,32,3)\n",
        "model = MiniModel(input_shape)\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 32, 32, 32)   896         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 32, 32, 32)   128         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 32, 32, 32)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 32, 32, 32)   9248        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 32, 32, 32)   128         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 32, 32, 32)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 32, 32, 32)   9248        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 32, 32, 32)   0           conv2d_65[0][0]                  \n",
            "                                                                 conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 32, 32, 32)   128         add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 32, 32, 32)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 32, 32, 32)   9248        activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 32, 32, 32)   128         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 32, 32, 32)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 32, 32, 32)   9248        activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 32, 32, 32)   0           add_28[0][0]                     \n",
            "                                                                 conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 32, 32, 32)   128         add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 32, 32, 32)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 32, 32, 32)   9248        activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 32, 32, 32)   128         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 32, 32, 32)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 32, 32, 32)   9248        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 32, 32, 32)   0           add_29[0][0]                     \n",
            "                                                                 conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 32)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 32)   128         max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 32)   0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 16, 16, 64)   18496       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 64)   256         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 64)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 16, 16, 64)   2112        add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 16, 16, 64)   36928       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 16, 16, 64)   0           conv2d_72[0][0]                  \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 64)   256         add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 64)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 16, 16, 64)   36928       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 16, 16, 64)   256         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 16, 16, 64)   0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 16, 16, 64)   36928       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 16, 16, 64)   0           add_31[0][0]                     \n",
            "                                                                 conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 16, 16, 64)   256         add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 16, 16, 64)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 16, 16, 64)   36928       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 16, 16, 64)   256         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 16, 16, 64)   0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 16, 16, 64)   36928       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 16, 16, 64)   0           add_32[0][0]                     \n",
            "                                                                 conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 64)     0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 64)     256         max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 64)     0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 128)    73856       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 128)    512         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 128)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 128)    8320        add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 128)    147584      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 8, 8, 128)    0           conv2d_79[0][0]                  \n",
            "                                                                 conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 128)    512         add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 128)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 128)    147584      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 128)    512         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 128)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 128)    147584      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 8, 8, 128)    0           add_34[0][0]                     \n",
            "                                                                 conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 8, 8, 128)    512         add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 128)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 128)    147584      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 8, 8, 128)    512         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 128)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 128)    147584      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 8, 8, 128)    0           add_35[0][0]                     \n",
            "                                                                 conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 4, 4, 128)    0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 4, 4, 128)    512         max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 4, 4, 128)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 4, 4, 256)    295168      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 4, 4, 256)    1024        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 4, 4, 256)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 4, 4, 256)    33024       add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 4, 4, 256)    590080      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 4, 4, 256)    0           conv2d_86[0][0]                  \n",
            "                                                                 conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 4, 4, 256)    1024        add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 4, 4, 256)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 4, 4, 256)    590080      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 4, 4, 256)    1024        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 4, 4, 256)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 4, 4, 256)    590080      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 4, 4, 256)    0           add_37[0][0]                     \n",
            "                                                                 conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 4, 4, 256)    1024        add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 4, 4, 256)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 4, 4, 256)    590080      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 4, 4, 256)    1024        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 4, 4, 256)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 4, 4, 256)    590080      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 4, 4, 256)    0           add_38[0][0]                     \n",
            "                                                                 conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 4, 4, 256)    1024        add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 4, 4, 256)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 4, 4, 256)    0           activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 1, 1, 256)    0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 256)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           2570        flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,374,538\n",
            "Trainable params: 4,368,714\n",
            "Non-trainable params: 5,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY6Qv-kZtzIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training components\n",
        "\n",
        "model.compile(optimizer=Adam(0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fm7rQ2yviTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "epochs = 50\n",
        "steps_per_epoch = ceil(50000/128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFVBwML7uDI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5ec40436-79c3-458d-81ab-34febdfd5213"
      },
      "source": [
        "# Fit the model on the batches generated by datagen.flow()\n",
        "\n",
        "model.fit_generator(datagen.flow(train_x, train_y, batch_size=128),\n",
        "                    validation_data=[test_x,test_y],\n",
        "                    epochs=epochs,steps_per_epoch=steps_per_epoch, verbose=1, workers=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "249/391 [==================>...........] - ETA: 14:13 - loss: 1.5840 - acc: 0.4099"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp6Nztywu37c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate the accuracy of the test dataset\n",
        "accuracy = model.evaluate(x=test_x,y=test_y,batch_size=128)\n",
        "model.save(\"cifar10model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYkUFknNk_hw",
        "colab_type": "text"
      },
      "source": [
        "Las funciones de callback que vamos a usar son EarlyStopping, para que el entrenamiento pare si ve que no mejora la función de coste tras determinados epochs, y ReduceLROnPlateau, que si el entrenamiento no mejora tras unos epochs específicos, reduce el valor de learning rate del modelo, lo que normalmente obtiene una mejora del entrenamiento.\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, min_delta=1e-4)  \n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4)  \n",
        "callbacks_list = [early_stop, reduce_lr]  \n",
        "model_history = model.fit_generator(  \n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size,\n",
        "    callbacks=callbacks_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTTq8cEhl2jk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "4abf20c3-e7a3-47be-be86-8e99690b032c"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h13kP3lIsqAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}