{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutonomousVehicles_ResNet50",
      "provenance": [],
      "authorship_tag": "ABX9TyOyax+iN0CeBmtssKVne1aF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suribe1010/Kaggle/blob/master/AutonomousVehicles_ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dkf44PpFzl8I",
        "colab_type": "text"
      },
      "source": [
        "This is a script for me to understand how to implement a CNN ResNet50 in autonomous vehicles, in real-time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIJzNBSBzo3A",
        "colab_type": "code",
        "outputId": "c8710d59-734c-49de-b06b-5777fe787132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "!git clone https://github.com/abhinavsagar/Self-Driving-Car.git\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Self-Driving-Car' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXaE0QepzTwb",
        "colab_type": "code",
        "outputId": "a708e9d3-6a52-44b1-e5b7-3ff5a8142ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls Self-Driving-Car"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "autonomous_car.ipynb  driving_log.csv  IMG  LICENSE  README.md\trun.gif\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpBTeqTozbdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## IMPORT NEEDED LIBRARIES\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as npimg\n",
        "import os\n",
        "\n",
        "## Keras\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import random\n",
        "import ntpath\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzJ1iV8507ep",
        "colab_type": "code",
        "outputId": "54c890a7-d25c-4d27-aeec-c1e043f2aea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "## STORE DATA\n",
        "datadir = 'Self-Driving-Car'\n",
        "columns = ['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed']\n",
        "data = pd.read_csv(os.path.join(datadir, 'driving_log.csv'), names = columns)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>center</th>\n",
              "      <th>left</th>\n",
              "      <th>right</th>\n",
              "      <th>steering</th>\n",
              "      <th>throttle</th>\n",
              "      <th>reverse</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\center_2019_07_22_20_38_15_382.jpg</td>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\left_2019_07_22_20_38_15_382.jpg</td>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\right_2019_07_22_20_38_15_382.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\center_2019_07_22_20_38_15_526.jpg</td>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\left_2019_07_22_20_38_15_526.jpg</td>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\right_2019_07_22_20_38_15_526.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\center_2019_07_22_20_38_15_669.jpg</td>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\left_2019_07_22_20_38_15_669.jpg</td>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\right_2019_07_22_20_38_15_669.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\center_2019_07_22_20_38_15_802.jpg</td>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\left_2019_07_22_20_38_15_802.jpg</td>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\right_2019_07_22_20_38_15_802.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\center_2019_07_22_20_38_15_937.jpg</td>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\left_2019_07_22_20_38_15_937.jpg</td>\n",
              "      <td>C:\\Users\\Win 10\\Desktop\\benign\\IMG\\right_2019_07_22_20_38_15_937.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000080</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                  center  ...     speed\n",
              "0  C:\\Users\\Win 10\\Desktop\\benign\\IMG\\center_2019_07_22_20_38_15_382.jpg  ...  0.000079\n",
              "1  C:\\Users\\Win 10\\Desktop\\benign\\IMG\\center_2019_07_22_20_38_15_526.jpg  ...  0.000082\n",
              "2  C:\\Users\\Win 10\\Desktop\\benign\\IMG\\center_2019_07_22_20_38_15_669.jpg  ...  0.000078\n",
              "3  C:\\Users\\Win 10\\Desktop\\benign\\IMG\\center_2019_07_22_20_38_15_802.jpg  ...  0.000078\n",
              "4  C:\\Users\\Win 10\\Desktop\\benign\\IMG\\center_2019_07_22_20_38_15_937.jpg  ...  0.000080\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hduOjJm014Se",
        "colab_type": "code",
        "outputId": "6095dcca-663e-45a6-c26e-3fb20370b066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "## VISUALIZE THE DATA\n",
        "\n",
        "num_bins = 25\n",
        "samples_per_bin = 200\n",
        "hist, bins = np.histogram(data['steering'], num_bins)\n",
        "center = bins[:-1] + bins[1:] #center the bins to 0\n",
        "\n",
        "# Plot\n",
        "\n",
        "plt.bar(center, hist, width=0.05)\n",
        "print('Bins: ', bins)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bins:  [-1.   -0.92 -0.84 -0.76 -0.68 -0.6  -0.52 -0.44 -0.36 -0.28 -0.2  -0.12\n",
            " -0.04  0.04  0.12  0.2   0.28  0.36  0.44  0.52  0.6   0.68  0.76  0.84\n",
            "  0.92  1.  ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGPqS1BFDX5I68v8ABBWkNssovvAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luDFOeLx-VJx",
        "colab_type": "code",
        "outputId": "c40fab4c-dfd6-4fb2-cca0-e3aecb53992a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "## REMOVE DATA STEERING = 0, GOING STRAIGHT\n",
        "remove_list = []\n",
        "for j in range(num_bins):\n",
        "  list_ = []\n",
        "  for i in range(len(data['steering'])):\n",
        "    steering_angle = data['steering'][i]\n",
        "    if steering_angle >= bins[j] and steering_angle <= bins[j+1]:\n",
        "      list_.append(i)\n",
        "  list_ = shuffle(list_)\n",
        "  list_ = list_[samples_per_bin:]\n",
        "  remove_list.extend(list_)\n",
        "  \n",
        "## Remove from extras from list\n",
        "data.drop(data.index[remove_list], inplace=True)\n",
        "print('Removed: {0}'.format(len(remove_list)))\n",
        "print('Remaining: {0}'.format(len(data)))\n",
        "\n",
        "## Plot\n",
        "hist, _ = np.histogram(data['steering'], (num_bins))\n",
        "plt.bar(center, hist, width=0.05)\n",
        "plt.plot((np.min(data['steering']), np.max(data['steering'])), (samples_per_bin, samples_per_bin))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removed: 1203\n",
            "Remaining: 540\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f16df684358>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZaEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0EgwDxGAueD",
        "colab_type": "code",
        "outputId": "fd52ee97-b589-4db6-a0cf-ceaf5c71f97c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "## IMAGE AND STEERING DATA INTO ARRAYS\n",
        "\n",
        "def load_img_steering(datadir, df):\n",
        "  \n",
        "  image_path = []\n",
        "  steering = []\n",
        "  for i in range(len(data)):\n",
        "    indexed_data = data.iloc[i]\n",
        "    center, left, right = indexed_data[0], indexed_data[1], indexed_data[2]\n",
        "    image_path.append(os.path.join(datadir, center.strip()))\n",
        "    steering.append(float(indexed_data[3]))\n",
        "  image_paths = np.asarray(image_path)\n",
        "  steerings = np.asarray(steering)\n",
        "  return image_paths, steerings\n",
        "\n",
        "image_paths, steerings = load_img_steering(datadir + '/IMG', data)\n",
        "print('Image Paths: ', image_paths[:8])\n",
        "print('Steerings: ', steerings[:30])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Paths:  ['Self-Driving-Car/IMG/C:\\\\Users\\\\Win 10\\\\Desktop\\\\benign\\\\IMG\\\\center_2019_07_22_20_38_15_937.jpg'\n",
            " 'Self-Driving-Car/IMG/C:\\\\Users\\\\Win 10\\\\Desktop\\\\benign\\\\IMG\\\\center_2019_07_22_20_38_17_547.jpg'\n",
            " 'Self-Driving-Car/IMG/C:\\\\Users\\\\Win 10\\\\Desktop\\\\benign\\\\IMG\\\\center_2019_07_22_20_38_17_823.jpg'\n",
            " 'Self-Driving-Car/IMG/C:\\\\Users\\\\Win 10\\\\Desktop\\\\benign\\\\IMG\\\\center_2019_07_22_20_38_18_123.jpg'\n",
            " 'Self-Driving-Car/IMG/C:\\\\Users\\\\Win 10\\\\Desktop\\\\benign\\\\IMG\\\\center_2019_07_22_20_38_18_495.jpg'\n",
            " 'Self-Driving-Car/IMG/C:\\\\Users\\\\Win 10\\\\Desktop\\\\benign\\\\IMG\\\\center_2019_07_22_20_38_18_633.jpg'\n",
            " 'Self-Driving-Car/IMG/C:\\\\Users\\\\Win 10\\\\Desktop\\\\benign\\\\IMG\\\\center_2019_07_22_20_38_18_893.jpg'\n",
            " 'Self-Driving-Car/IMG/C:\\\\Users\\\\Win 10\\\\Desktop\\\\benign\\\\IMG\\\\center_2019_07_22_20_38_19_514.jpg']\n",
            "Steerings:  [ 0.        -1.        -0.1616194  0.        -0.713801  -0.293242\n",
            "  0.        -0.5423487 -0.9730906 -1.         0.        -0.7876602\n",
            " -0.1776071 -0.8362509  0.         0.         0.        -0.5763551\n",
            " -0.8140205 -1.        -0.2999952  0.         0.7109125  0.1537359\n",
            "  0.851765   1.         1.         1.         1.         1.       ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkwGeuxFO4J2",
        "colab_type": "code",
        "outputId": "42deba7b-4063-4a0a-a430-c2dee04e05a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "## DIVIDE DATA AND CHECK THAT IS VALID\n",
        "#The next step was to split the data using the 80â€“20 rule which means using 80% of the data for training while the rest for testing the model on unseen images. Also, I plotted the sample training and validation steering angle distributions.\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(image_paths, steerings, test_size=0.2, random_state=0)\n",
        "\n",
        "## Check that data is valid\n",
        "print(\"Training Samples: {}\\nValid Samples: {}\".format(len(X_train), len(X_valid)))\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axes[0].hist(Y_train, bins=num_bins, width=0.05, color='blue')\n",
        "axes[0].set_title('Training set')\n",
        "axes[1].hist(Y_valid, bins=num_bins, width=0.05, color='red')\n",
        "axes[1].set_title('Validation set')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Samples: 432\n",
            "Valid Samples: 108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Validation set')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAEICAYAAABcYjLsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/j8FPdBb3FgPMwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0OKW8rkQuqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## IMAGE PREPROCESSING\n",
        "#I continued by doing some image processing. I cropped the image to remove the unnecessary features, changes the images to YUV format, \n",
        "#used gaussian blur, decreased the size for easier processing and normalized the values.\n",
        "def img_preprocess(img):\n",
        "  \"\"\"Take in path of img, returns preprocessed image\"\"\"\n",
        "  img = npimg.imread(img)\n",
        "  \n",
        "  ## Crop image to remove unnecessary features\n",
        "  img = img[60:135, :, :]\n",
        "  \n",
        "  ## Change to YUV image\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
        "  \n",
        "  ## Gaussian blur\n",
        "  img = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "  \n",
        "  ## Decrease size for easier processing\n",
        "  img = cv2.resize(img, (100, 100))\n",
        "  \n",
        "  ## Normalize values\n",
        "  img = img / 255\n",
        "  return img\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLl5XZ8wUECf",
        "colab_type": "code",
        "outputId": "6ee9479c-bd1a-4dae-d422-3174a7468941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "## Get any image\n",
        "image = image_paths[100]\n",
        "#original_image = npimg.imread(image)\n",
        "preprocessed_image = img_preprocess(image)\n",
        "\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-c3e76f030422>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#original_image = npimg.imread(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreprocessed_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-d7ec786c23ce>\u001b[0m in \u001b[0;36mimg_preprocess\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimg_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;34m\"\"\"Take in path of img, returns preprocessed image\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m## Crop image to remove unnecessary features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1415\u001b[0m                              \u001b[0;34m'with Pillow installed matplotlib can handle '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                              'more images' % list(handlers))\n\u001b[0;32m-> 1417\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Self-Driving-Car/IMG/C:\\\\Users\\\\Win 10\\\\Desktop\\\\benign\\\\IMG\\\\center_2019_07_22_20_39_35_548.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgIpwEXoUn0v",
        "colab_type": "code",
        "outputId": "b199a8af-a685-4cd0-baea-899c99024f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "## Converted all the images into numpy array\n",
        "\n",
        "X_train = np.array(list(map(img_preprocess, X_train)))\n",
        "X_valid = np.array(list(map(img_preprocess, X_valid)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-ce30c9bcf1f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_preprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_preprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-d7ec786c23ce>\u001b[0m in \u001b[0;36mimg_preprocess\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimg_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;34m\"\"\"Take in path of img, returns preprocessed image\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m## Crop image to remove unnecessary features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1415\u001b[0m                              \u001b[0;34m'with Pillow installed matplotlib can handle '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                              'more images' % list(handlers))\n\u001b[0;32m-> 1417\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Self-Driving-Car/IMG/C:\\\\Users\\\\Win 10\\\\Desktop\\\\benign\\\\IMG\\\\center_2019_07_22_20_38_22_360.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8NAB6mdWAMd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86b0a523-074f-4830-d178-273e5a865ed7"
      },
      "source": [
        "## Build the model. I have used ResNet as the pre-trained weights. I have removed the last 4 layers to make my own custom neural network.\n",
        "\n",
        "from keras.applications import ResNet50\n",
        "#Load the ResNet50 model\n",
        "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
        "\n",
        "#I have removed the last 4 layers to make my own custom neural network.\n",
        "# Freeze the layers except the last 4 layers\n",
        "for layer in resnet.layers[:-4]:\n",
        "    layer.trainable = False\n",
        " \n",
        "for layer in resnet.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 2s 0us/step\n",
            "<keras.engine.input_layer.InputLayer object at 0x7f16df4d8588> False\n",
            "<keras.layers.convolutional.ZeroPadding2D object at 0x7f16df4d8828> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16df4d89b0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16df4ee7f0> False\n",
            "<keras.layers.core.Activation object at 0x7f16df4eedd8> False\n",
            "<keras.layers.convolutional.ZeroPadding2D object at 0x7f16df4fa828> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f16d9205b00> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d9227e80> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d922f2e8> False\n",
            "<keras.layers.core.Activation object at 0x7f16d922ff60> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d92374e0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d91f1390> False\n",
            "<keras.layers.core.Activation object at 0x7f16d91f1320> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d91f9ef0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d91b4320> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d91b4390> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d917d2e8> False\n",
            "<keras.layers.merge.Add object at 0x7f16d917d208> False\n",
            "<keras.layers.core.Activation object at 0x7f16d913af60> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d911ec50> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d90c1b70> False\n",
            "<keras.layers.core.Activation object at 0x7f16d90c9e80> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d90c9f28> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d9087438> False\n",
            "<keras.layers.core.Activation object at 0x7f16d9091f60> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d90974e0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d904f4a8> False\n",
            "<keras.layers.merge.Add object at 0x7f16d9057dd8> False\n",
            "<keras.layers.core.Activation object at 0x7f16d9069f98> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d90085f8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d9014ef0> False\n",
            "<keras.layers.core.Activation object at 0x7f16d901ef60> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d9025780> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8fdc780> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8fdc710> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8fed2b0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8fa47f0> False\n",
            "<keras.layers.merge.Add object at 0x7f16d8fa4780> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8fbfd30> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8f47e48> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8f6be48> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8f716a0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8f782e8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8f30a20> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8f30f98> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8f3e358> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8efd0b8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8ef6a90> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8ebfa90> False\n",
            "<keras.layers.merge.Add object at 0x7f16d8ebfba8> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8e5ce10> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8e63f98> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8e06f98> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8e0f7b8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8e143c8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8dceb38> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8dd5080> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8ddb470> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8d96ba8> False\n",
            "<keras.layers.merge.Add object at 0x7f16d8d9c0f0> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8db2860> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8db2eb8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8d647f0> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8d64b00> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8d69780> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8d22e80> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8d28390> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8d307b8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8ce8eb8> False\n",
            "<keras.layers.merge.Add object at 0x7f16d8cee400> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8c83d68> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8ca7128> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16e2699320> False\n",
            "<keras.layers.core.Activation object at 0x7f16df631a20> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16df71d550> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16df742da0> False\n",
            "<keras.layers.core.Activation object at 0x7f16e2822400> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16e28146d8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16e240ec18> False\n",
            "<keras.layers.merge.Add object at 0x7f16e240ed68> False\n",
            "<keras.layers.core.Activation object at 0x7f16e2474e48> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16df9e1908> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16dfb31e10> False\n",
            "<keras.layers.core.Activation object at 0x7f16dfb313c8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16e28131d0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16df743780> False\n",
            "<keras.layers.core.Activation object at 0x7f16df743710> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16df7352b0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8c52780> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8c527f0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8c09e48> False\n",
            "<keras.layers.merge.Add object at 0x7f16d8c09f60> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8c20898> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8c20ef0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8bcdf28> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8bd6eb8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8bdc6d8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8b926d8> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8b92668> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8ba0198> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8b57710> False\n",
            "<keras.layers.merge.Add object at 0x7f16d8b576a0> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8b73c88> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8b78da0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8b209e8> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8b20cf8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8b28b38> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8ae5198> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8ae50f0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8aecba8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8aa81d0> False\n",
            "<keras.layers.merge.Add object at 0x7f16d8aa8160> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8abea20> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8a626a0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8a6ffd0> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8a75780> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8a7e3c8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8a35b00> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8a39048> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d89c1438> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d89f9b70> False\n",
            "<keras.layers.merge.Add object at 0x7f16d89fe0b8> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8993828> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8993fd0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8944a58> False\n",
            "<keras.layers.core.Activation object at 0x7f16d894bdd8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8950630> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8909630> False\n",
            "<keras.layers.core.Activation object at 0x7f16d89095c0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d89160b8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d88cd6a0> False\n",
            "<keras.layers.merge.Add object at 0x7f16d88d4ef0> False\n",
            "<keras.layers.core.Activation object at 0x7f16d88e9fd0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d88efcf8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8897940> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8897c50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d88a0a90> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8856f28> False\n",
            "<keras.layers.core.Activation object at 0x7f16d885c048> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8864cc0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8821128> False\n",
            "<keras.layers.merge.Add object at 0x7f16d88210b8> False\n",
            "<keras.layers.core.Activation object at 0x7f16d883cf98> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d87d75f8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d87e4ef0> False\n",
            "<keras.layers.core.Activation object at 0x7f16d87eb6d8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d87f12b0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d87a7a58> False\n",
            "<keras.layers.core.Activation object at 0x7f16d87ae0f0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d87b5390> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d87760b8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d876dac8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8739208> False\n",
            "<keras.layers.merge.Add object at 0x7f16d8739128> False\n",
            "<keras.layers.core.Activation object at 0x7f16d86dafd0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d86f5518> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8700e10> False\n",
            "<keras.layers.core.Activation object at 0x7f16d8688630> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d8692240> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8644a58> False\n",
            "<keras.layers.core.Activation object at 0x7f16d86449e8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d86592e8> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d860fa20> False\n",
            "<keras.layers.merge.Add object at 0x7f16d860ff98> False\n",
            "<keras.layers.core.Activation object at 0x7f16d862c6d8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d862cfd0> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d85ddd68> False\n",
            "<keras.layers.core.Activation object at 0x7f16d85e6f98> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d85eb518> False\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d85a34e0> False\n",
            "<keras.layers.core.Activation object at 0x7f16d85b2588> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f16d85c0f98> True\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7f16d8569550> True\n",
            "<keras.layers.merge.Add object at 0x7f16d8572dd8> True\n",
            "<keras.layers.core.Activation object at 0x7f16d8507f98> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWsArS5SW-Z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nvidia_model():\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(resnet)#pre-trained model\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Flatten()) # On top of the heavy resnet architecture, I have used the flatten layer to normalize the weights. \n",
        "  \n",
        "  model.add(Dense(100, activation='elu')) #three dense layers with 100, 50 and 10 neurons\n",
        "  model.add(Dropout(0.5)) #50% dropouts to reduce over-fitting the values to the training set.\n",
        "  \n",
        "  model.add(Dense(50, activation='elu'))# elu as the activation function\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Dense(10, activation='elu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Dense(1))\n",
        "  \n",
        "  optimizer = Adam(lr=1e-3)\n",
        "  model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcLViaNqXUjM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "17fcd3e3-5723-4002-89ba-04be8f069fcd"
      },
      "source": [
        "model = nvidia_model()\n",
        "print(model.summary())"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4, 4, 2048)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               3276900   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                510       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 26,870,183\n",
            "Trainable params: 4,337,191\n",
            "Non-trainable params: 22,532,992\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69QvX7JmXeS7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "2380c4de-ad82-4f2e-b172-87ced765e3cb"
      },
      "source": [
        "history = model.fit(X_train, Y_train, epochs=25, validation_data=(X_valid, Y_valid), batch_size=128, verbose=1, shuffle=1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-adb48fcf6b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected resnet50_input to have 4 dimensions, but got array with shape (432, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yAn2tY2YPmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "4b8b6a11-a8a8-4cfa-862d-587323d71d63"
      },
      "source": [
        "#Finally, I trained the model for 25 epochs with a batch size of 128. \n",
        "#Also, I plotted the training and the validation loss as a function of epochs.\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training', 'validation'])\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-31aaed67083e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzl36i95YqQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}