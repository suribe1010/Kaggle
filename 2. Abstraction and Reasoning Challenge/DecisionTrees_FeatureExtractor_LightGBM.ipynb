{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport json\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from pathlib import Path\n\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'\n\ntraining_tasks = sorted(os.listdir(training_path))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ======================================================================================\n# USING DECISIONS TREES\n# ======================================================================================\n\n# IMPORT LIBRARIES AND DATASETS\nimport numpy as np\nimport pandas as pd\n\nimport os\nimport json\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np\nfrom lightgbm import LGBMClassifier\nimport pdb\n\nfrom pathlib import Path\n\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'\n\ntraining_tasks = sorted(os.listdir(test_path))\n\nsample_sub = pd.read_csv(data_path/'sample_submission.csv')\nsample_sub = sample_sub.set_index('output_id')\nsample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLOTING FUNCTION\n\ndef plot_result(test_input, test_prediction,\n                input_shape):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 2, figsize=(15,15))\n    test_input = test_input.reshape(input_shape[0],input_shape[1])\n    axs[0].imshow(test_input, cmap=cmap, norm=norm)\n    axs[0].axis('off')\n    axs[0].set_title('Actual Target')\n    test_prediction = test_prediction.reshape(input_shape[0],input_shape[1])\n    axs[1].imshow(test_prediction, cmap=cmap, norm=norm)\n    axs[1].axis('off')\n    axs[1].set_title('Model Prediction')\n    plt.tight_layout()\n    plt.show()\n    \ndef plot_test(test_prediction, task_name):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 1, figsize=(15,15))\n    axs.imshow(test_prediction, cmap=cmap, norm=norm)\n    axs.axis('off')\n    axs.set_title(f'Test Prediction {task_name}')\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FOR FLATTENING 2D NUMPY ARRAYS\n\n# https://www.kaggle.com/inversion/abstraction-and-reasoning-starter-notebook\ndef flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EXTRACT NEIGHBOURHOOD FEATURES\n\ndef get_moore_neighbours(color, cur_row, cur_col, nrows, ncols):\n\n    if cur_row<=0: top = -1\n    else: top = color[cur_row-1][cur_col]\n        \n    if cur_row>=nrows-1: bottom = -1\n    else: bottom = color[cur_row+1][cur_col]\n        \n    if cur_col<=0: left = -1\n    else: left = color[cur_row][cur_col-1]\n        \n    if cur_col>=ncols-1: right = -1\n    else: right = color[cur_row][cur_col+1]\n        \n    return top, bottom, left, right\n\ndef get_tl_tr(color, cur_row, cur_col, nrows, ncols):\n        \n    if cur_row==0:\n        top_left = -1\n        top_right = -1\n    else:\n        if cur_col==0: top_left=-1\n        else: top_left = color[cur_row-1][cur_col-1]\n        if cur_col==ncols-1: top_right=-1\n        else: top_right = color[cur_row-1][cur_col+1]   \n        \n    return top_left, top_right","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FEATURES FOR EACH TRAIN SAMPLE\n\ndef features(task, mode = 'train'):\n    current_index = 0\n    number_train_pairs = len(task[mode])\n    \n    # Inputs = all  the values of all matrices of the training images\n    total_inputs = sum([len(task[mode][i]['input'])*len(task[mode][i]['input'][0]) for i in range(number_train_pairs)])\n    \n    # Feature\n    feature = np.zeros((total_inputs, number_features))\n    \n    #Output\n    target = np.zeros((total_inputs,), dtype = np.int) #we don't specify the dimensions, but by default=1\n    \n    # Global is used to create global variables from a non-global scope i.e inside a function.\n    # Global keyword is used inside a function only when we want to do assignments or when we want to change a variable\n    global local_neighbours\n    \n    for task_number in range(number_train_pairs):\n        # Input coloured image\n        input_color = np.array(task[mode][task_number]['input'])\n        \n        # Target coloured image\n        target_color = task[mode][task_number]['output']\n    \n        # Number of rows, columns of the input image\n        input_rows, input_columns = len(task[mode][task_number]['input']), len(task[mode][task_number]['input'][0])\n        \n        # Number of rows, columns of the output image\n        target_rows, target_columns = len(task[mode][task_number]['output']), len(task[mode][task_number]['output'][0])\n        \n        if (target_rows != input_rows) or (target_columns != input_columns):\n            print('Number of input rows:',input_rows,'cols:',input_columns)\n            print('Number of target rows:',target_rows,'cols:',target_columns)\n            not_valid=1\n            return None, None, 1\n        \n        for i in range (input_rows):\n            for j in range(input_columns):\n                feature[current_index, 0] = i\n                feature[current_index,1] = j\n                feature[current_index,2] = input_color[i][j]\n                feature[current_index,3:7] = get_moore_neighbours(input_color, i, j, input_rows, input_columns)\n                feature[current_index,7:9] = get_tl_tr(input_color, i, j, input_rows, input_columns)\n                feature[current_index,9] = len(np.unique(input_color[i,:]))\n                feature[current_index,10] = len(np.unique(input_color[:,j]))\n                feature[current_index,11] = (i+j)\n                feature[current_index,12] = len(np.unique(input_color[i-local_neighbours:i+local_neighbours,\n                                                             j-local_neighbours:j+local_neighbours]))\n        \n                target[current_index] = target_color[i][j]\n                current_index += 1\n        \n        \n    return feature, target, 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## TRAINING AND PREDICTION\n\nall_task_ids = sorted(os.listdir(test_path))# test dataset\n\nnumber_features = 13\nlocal_neighbours = 3\nvalid_scores = {}\nfor task_id in all_task_ids:\n\n    task_file = str(test_path / task_id)\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n        \n    feature, target,not_valid = features(task)\n    if not_valid:\n        print('ignoring task', task_file)\n        print()\n        not_valid = 0\n        continue\n        \n        \n    # we use the last train example for validation\n    input_rows, input_columns = len(task['train'][-1]['input']), len(task['train'][-1]['input'][0]) # index -1 stands for the last training pair\n    validation_index = len(feature) - input_rows*input_columns\n    \n    train_features = feature[:validation_index]\n    validation_features = feature[validation_index:, :]\n\n    train_target = target[:validation_index]\n    validation_target = target[validation_index:]\n    \n    \n    #     check if validation set has a new color  --> with set() -> if a = {1,1,3,4,5,5} --> set(a) = {1,3,4,5}\n    #     if so make the mapping color independant\n    if len(set(validation_target) - set(train_target)):\n        print('set(val_target)', set(validation_target))\n        print('set(train_target)', set(train_target))\n        print('Number of colors are not same')\n        print('cant handle new colors. skipping')\n        continue\n\n    # LIGHT GBM ALGORITHM:\n    # https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc\n    # Light GBM grows tree vertically while other algorithm grows trees horizontally meaning that Light GBM grows tree leaf-wise while other algorithm grows level-wise.\n    lgb = LGBMClassifier(n_estimators=50, n_jobs=-1) #initialise\n    lgb.fit(feature, target, verbose=-1)\n    \n    #training in input pairs is done\n    \n    \n    #---------------------------------------------------------\n    #TESTING\n    num_test_pairs = len(task['test'])\n    for task_num in range(num_test_pairs):\n        current_index = 0\n        input_color = np.array(task['test'][task_num]['input'])\n        input_rows, input_columns = len(task['test'][task_num]['input']), len(task['test'][task_num]['input'][0])\n        feature = np.zeros((input_rows*input_columns, number_features))\n        unique_col = {column: i for i, column in enumerate(sorted(np.unique(input_color)))} # identify the colours that appear and enumerate them 1, 2,...\n        \n        for i in range(input_rows):\n            for j in range(input_columns):\n                feature[current_index, 0] = i\n                feature[current_index, 1] = j\n                feature[current_index, 2] = input_color[i][j]\n                feature[current_index, 3:7] = get_moore_neighbours(input_color, i, j, input_rows, input_columns)\n                feature[current_index, 7:9] = get_tl_tr(input_color, i, j, input_rows, input_columns)\n                feature[current_index, 9] = len(np.unique(input_color[i, :]))\n                feature[current_index, 10] = len(np.unique(input_color[:, j]))\n                feature[current_index, 11] = (i+j)\n                feature[current_index, 12] = len(np.unique(input_color[i-local_neighbours:i+local_neighbours,j-local_neighbours:j+local_neighbours]))\n                current_index += 1\n                \n        print('Made predictions for ', task_id[:-5])\n        preds = lgb.predict(feature).reshape(input_rows, input_columns)\n        preds = preds.astype(int).tolist()\n        plot_test(preds, task_id)\n        sample_sub.loc[f'{task_id[:-5]}_{task_num}', 'output'] = flattener(preds)\n    \n    \n    \n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub.to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}